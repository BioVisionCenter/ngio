{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to NGIO","text":"<p>NGIO is a Python library to streamline OME-Zarr image analysis workflows.</p> <p>Main Goals:</p> <ul> <li>Abstract object base API for handling OME-Zarr files</li> <li>Powefull iterators for processing data using common access patterns</li> <li>Tight integration with Fractal's Table Fractal</li> <li>Validate OME-Zarr files</li> </ul> <p>To get started, check out the Getting Started guide.</p>"},{"location":"#ngio-is-under-active-development","title":"\ud83d\udea7 Ngio is Under active Development \ud83d\udea7","text":""},{"location":"#roadmap","title":"Roadmap","text":"Feature Status ETA Description Metadata Handling \u2705 Read, Write, Validate OME-Zarr Metadata (0.4 supported, 0.5 ready) OME-Zarr Validation \u2705 Validate OME-Zarr files for compliance with the OME-Zarr Specification + Compliance between Metadata and Data Base Image Handling \u2705 Load data from OME-Zarr files, retrieve basic metadata, and write data ROI Handling \u2705 Common ROI models Label Handling \u2705 Mid-September Based on Image Handling Table Validation \u2705 Mid-September Validate Table fractal V1 + Compliance between Metadata and Data Table Handling \u2705 Mid-September Read, Write ROI, Features, and Masked Tables Basic Iterators Ongoing End-September Read and Write Iterators for common access patterns Base Documentation \u2705 End-September API Documentation and Examples Beta Ready Testing \u2705 End-September Beta Testing; Library is ready for testing, but the API is not stable Streaming from Fractal Ongoing December Ngio can stream ome-zarr from fractal Mask Iterators Ongoing Early 2025 Iterators over Masked Tables Advanced Iterators Not started mid-2025 Iterators for advanced access patterns Parallel Iterators Not started mid-2025 Concurrent Iterators for parallel read and write Full Documentation Not started 2025 Complete Documentation Release 1.0 (Commitment to API) Not started 2025 API is stable; breaking changes will be avoided"},{"location":"#contributors","title":"Contributors","text":"<p><code>ngio</code> is developed at the BioVisionCenter at the University of Zurich. The main contributors are: @lorenzocerrone, @jluethi.</p>"},{"location":"#license","title":"License","text":"<p><code>ngio</code> is released according to the BSD-3-Clause License. See LICENSE</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Warning</p> <p>The library is still in development and is not yet stable. The API is subject to change, bugs and breaking changes are expected.</p> <p>Warning</p> <p>The documentation is still under development. It is not yet complete and may contain errors and inaccuracies.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>The library can be installed from PyPI using pip:</p> <pre><code>pip install \"ngio[core]\"\n</code></pre> <p>The <code>core</code> extra installs the the <code>zarr-python</code> dependency. As of now, <code>zarr-python</code> is required to be installed separately, due to the transition to the new <code>zarr-v3</code> library.</p>"},{"location":"getting-started/#ngio-api-overview","title":"<code>ngio</code> API Overview","text":"<p><code>ngio</code> implements an abstract object base API for handling OME-Zarr files. The three main objects are <code>NgffImage</code>, <code>Image</code> (<code>Label</code>), and <code>ROITables</code>.</p> <ul> <li><code>NgffImage</code> is the main entry point to the library. It is used to open an OME-Zarr Image and manage its metadata. This object can not be used to access the data directly.   but it can be used to access and create the <code>Image</code>, <code>Label</code>, and <code>Tables</code> objects. Moreover it can be used to derive a new <code>Ngff</code> images based on the current one.</li> <li><code>Image</code> and <code>Label</code> are used to access \"ImageLike\" objects. They are the main objects to access the data in the OME-Zarr file, manage the metadata, and write data.</li> <li><code>ROITables</code> can be used to access specific region of interest in the image. They are tightly integrated with the <code>Image</code> and <code>Label</code> objects.</li> </ul>"},{"location":"getting-started/#example-usage","title":"Example Usage","text":"<p>Currently, the library is not yet stable. However, you can see some example usage in our demo notebooks:</p> <ul> <li>Basic Usage</li> <li>Image/Label/Tables</li> <li>Processing</li> </ul>"},{"location":"api/core/","title":"ngio","text":"<p>Work in progress! Sorry!</p>"},{"location":"notebooks/basic_usage/","title":"OME-Zarr Image Exploration","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nfrom ngio import open_omezarr_container\nfrom ngio.utils import download_ome_zarr_dataset\n\n# Download the dataset\ndownload_dir = Path(\".\").absolute().parent.parent / \"data\"\nhcs_path = download_ome_zarr_dataset(\"CardiomyocyteSmallMip\", download_dir=download_dir)\nimage_path = hcs_path / \"B\" / \"03\" / \"0\"\n\n# Open the ome-zarr container\nomezarr_container = open_omezarr_container(image_path)\n</pre> from pathlib import Path  from ngio import open_omezarr_container from ngio.utils import download_ome_zarr_dataset  # Download the dataset download_dir = Path(\".\").absolute().parent.parent / \"data\" hcs_path = download_ome_zarr_dataset(\"CardiomyocyteSmallMip\", download_dir=download_dir) image_path = hcs_path / \"B\" / \"03\" / \"0\"  # Open the ome-zarr container omezarr_container = open_omezarr_container(image_path) <pre>Downloading data from 'https://zenodo.org/records/13305316/files/20200812-CardiomyocyteDifferentiation14-Cycle1_mip.zarr.zip' to file '/home/runner/work/ngio/ngio/data/20200812-CardiomyocyteDifferentiation14-Cycle1_mip.zarr.zip'.\n</pre> <pre>Unzipping contents of '/home/runner/work/ngio/ngio/data/20200812-CardiomyocyteDifferentiation14-Cycle1_mip.zarr.zip' to '/home/runner/work/ngio/ngio/data/'\n</pre> <p>The <code>omezarr_container</code> object provides a high-level interface to read, write and manipulate OME-Zarr images.</p> <p>Print the image will show some overview information like:</p> <ul> <li>The path to the image</li> <li>The multiscale pyramid paths</li> <li>The labels contained in the image</li> <li>The tables contained in the imag</li> </ul> In\u00a0[2]: Copied! <pre>print(omezarr_container)\n</pre> print(omezarr_container) <pre>OmeZarrContainer(levels=5, #labels=4, #tables=7)\n</pre> <p>From the <code>OmeZarr Container</code> object we can easily access access the image data (at any resolution level), the labels and the tables.</p> <p>Get a single <code>level</code> of the image pyramid as <code>Image</code> (to know more about the <code>Image</code> class, please refer to the Image notebook The <code>Image</code> object is the main object to interact with the image. It contains methods to interact with the image data and metadata.</p> In\u00a0[3]: Copied! <pre>from ngio import PixelSize\n\n# 1. Get image from highest resolution (default)\nimage = omezarr_container.get_image()\nprint(image)\n\n# 2. Get image from a specific level using the path keyword\nimage = omezarr_container.get_image(path=\"1\")\nprint(image)\n\n# 3. Get image from a specific pixel size using the pixel_size keyword\n# image = omezarr_container.get_image(\n#    pixel_size=PixelSize(x=0.65, y=0.65, z=1), strict=True\n# )\nprint(image.pixel_size == PixelSize(x=0.325, y=0.325, z=1))\n</pre> from ngio import PixelSize  # 1. Get image from highest resolution (default) image = omezarr_container.get_image() print(image)  # 2. Get image from a specific level using the path keyword image = omezarr_container.get_image(path=\"1\") print(image)  # 3. Get image from a specific pixel size using the pixel_size keyword # image = omezarr_container.get_image( #    pixel_size=PixelSize(x=0.65, y=0.65, z=1), strict=True # ) print(image.pixel_size == PixelSize(x=0.325, y=0.325, z=1)) <pre>Image(path=0, Dimensions(c: 3, z: 1, y: 4320, x: 5120))\nImage(path=1, Dimensions(c: 3, z: 1, y: 2160, x: 2560))\nTrue\n</pre> <p>The <code>Image</code> object provides a high-level interface to read and write image data at a specific resolution level.</p> In\u00a0[4]: Copied! <pre>print(\"Shape\", image.shape)\nprint(\"PixelSize\", image.pixel_size)\nprint(\"Dimensions\", image.dimensions)\nprint(\"Channel Names\", image.channel_labels)\n</pre> print(\"Shape\", image.shape) print(\"PixelSize\", image.pixel_size) print(\"Dimensions\", image.dimensions) print(\"Channel Names\", image.channel_labels) <pre>Shape (3, 1, 2160, 2560)\nPixelSize PixelSize(x=0.325, y=0.325, z=1.0, t=1.0)\nDimensions Dimensions(c: 3, z: 1, y: 2160, x: 2560)\nChannel Names ['DAPI', 'nanog', 'Lamin B1']\n</pre> In\u00a0[5]: Copied! <pre># Get data as a numpy array or a dask array\ndata = image.get_array(c=0, mode=\"numpy\")\nprint(data)\n\ndask_data = image.get_array(c=0, mode=\"dask\")\ndask_data\n</pre> # Get data as a numpy array or a dask array data = image.get_array(c=0, mode=\"numpy\") print(data)  dask_data = image.get_array(c=0, mode=\"dask\") dask_data <pre>[[[[295 274 275 ... 275 269 296]\n   [282 271 249 ... 232 268 264]\n   [274 271 299 ... 249 240 273]\n   ...\n   [196 199 185 ...   6   8   1]\n   [206 207 210 ...   4   3   7]\n   [187 237 243 ...   0   6  13]]]]\n</pre> Out[5]:  Array   Chunk   Bytes   10.55 MiB   10.55 MiB   Shape   (1, 1, 2160, 2560)   (1, 1, 2160, 2560)   Dask graph   1 chunks in 3 graph layers   Data type   uint16 numpy.ndarray  1 1 2560 2160 1 <p><code>ngio</code> design is to always provide the data in a canonical axis order (<code>t</code>, <code>c</code>, <code>z</code>, <code>y</code>, <code>x</code>) no matter what is the order on disk. The <code>Image</code> object provides methods to access the data in this order.</p> In\u00a0[6]: Copied! <pre>print(\"List of Labels: \", omezarr_container.list_labels())\n\nlabel_nuclei = omezarr_container.get_label(\"nuclei\", path=\"0\")\nprint(label_nuclei)\n</pre> print(\"List of Labels: \", omezarr_container.list_labels())  label_nuclei = omezarr_container.get_label(\"nuclei\", path=\"0\") print(label_nuclei) <pre>List of Labels:  ['nuclei', 'wf_2_labels', 'wf_3_labels', 'wf_4_labels']\nImage(path=0, Dimensions(z: 1, y: 4320, x: 5120))\n</pre> In\u00a0[7]: Copied! <pre>print(\"List of Tables: \", omezarr_container.list_tables())\n</pre> print(\"List of Tables: \", omezarr_container.list_tables()) <pre>List of Tables:  ['FOV_ROI_table', 'nuclei_ROI_table', 'well_ROI_table', 'regionprops_DAPI', 'nuclei_measurements_wf3', 'nuclei_measurements_wf4', 'nuclei_lamin_measurements_wf4']\n</pre> In\u00a0[8]: Copied! <pre># Loading a table\nfeature_table = omezarr_container.get_table(\"regionprops_DAPI\")\nfeature_table.dataframe\n</pre> # Loading a table feature_table = omezarr_container.get_table(\"regionprops_DAPI\") feature_table.dataframe <pre>/opt/hostedtoolcache/Python/3.13.2/x64/lib/python3.13/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n</pre> Out[8]: area bbox_area equivalent_diameter max_intensity mean_intensity min_intensity standard_deviation_intensity label 1 2120.0 2655.0 15.938437 476.0 278.635864 86.0 54.343792 2 327.0 456.0 8.547709 604.0 324.162079 118.0 90.847092 3 1381.0 1749.0 13.816510 386.0 212.682114 60.0 50.169601 4 2566.0 3588.0 16.985800 497.0 251.731491 61.0 53.307186 5 4201.0 5472.0 20.019413 466.0 223.862885 51.0 56.719025 ... ... ... ... ... ... ... ... 3002 1026.0 1288.0 12.513618 589.0 308.404480 132.0 64.681778 3003 859.0 1080.0 11.794101 400.0 270.349243 107.0 49.040470 3004 508.0 660.0 9.899693 314.0 205.043304 82.0 33.249981 3005 369.0 440.0 8.899028 376.0 217.970184 82.0 50.978519 3006 278.0 330.0 8.097459 339.0 217.996399 100.0 38.510067 <p>3006 rows \u00d7 7 columns</p> In\u00a0[9]: Copied! <pre># Loading a roi table\nroi_table = omezarr_container.get_table(\"FOV_ROI_table\")\n\nprint(f\"{roi_table.get('FOV_1')=}\")\n</pre> # Loading a roi table roi_table = omezarr_container.get_table(\"FOV_ROI_table\")  print(f\"{roi_table.get('FOV_1')=}\") <pre>roi_table.get('FOV_1')=WorldCooROI(name='FOV_1', x_length=416.0, y_length=351.0, z_length=1.0, x=0.0, y=0.0, z=0.0, x_micrometer_original=np.float32(-1448.3), y_micrometer_original=np.float32(-1517.7))\n</pre> <p>Rois can be used to index image and label data.</p> In\u00a0[10]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Plotting a single ROI\nroi = roi_table.get(\"FOV_1\")\nroi_data = image.get_roi(roi, c=0, mode=\"numpy\")\nplt.title(\"ROI: FOV_1\")\nplt.imshow(roi_data[0, 0], cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Plotting a single ROI roi = roi_table.get(\"FOV_1\") roi_data = image.get_roi(roi, c=0, mode=\"numpy\") plt.title(\"ROI: FOV_1\") plt.imshow(roi_data[0, 0], cmap=\"gray\") plt.axis(\"off\") plt.show() In\u00a0[11]: Copied! <pre>new_omezarr_image = omezarr_container.derive_image(\"data/new_ome.zarr\", overwrite=True)\nprint(new_omezarr_image)\n</pre> new_omezarr_image = omezarr_container.derive_image(\"data/new_ome.zarr\", overwrite=True) print(new_omezarr_image) <pre>OmeZarrContainer(levels=5)\n</pre> In\u00a0[12]: Copied! <pre>import numpy as np\n\nfrom ngio import create_omezarr_from_array\n\nx = np.random.randint(0, 255, (16, 128, 128), dtype=np.uint8)\n\nnew_omezarr_image = create_omezarr_from_array(\n    store=\"random_ome.zarr\", array=x, xy_pixelsize=0.65, z_spacing=1.0\n)\nprint(new_omezarr_image)\nprint(new_omezarr_image.get_image())\n</pre> import numpy as np  from ngio import create_omezarr_from_array  x = np.random.randint(0, 255, (16, 128, 128), dtype=np.uint8)  new_omezarr_image = create_omezarr_from_array(     store=\"random_ome.zarr\", array=x, xy_pixelsize=0.65, z_spacing=1.0 ) print(new_omezarr_image) print(new_omezarr_image.get_image()) <pre>OmeZarrContainer(levels=5)\nImage(path=0, Dimensions(z: 16, y: 128, x: 128))\n</pre> In\u00a0[13]: Copied! <pre>import fsspec\nimport fsspec.implementations.http\n\nurl = (\n    \"https://raw.githubusercontent.com/\"\n    \"fractal-analytics-platform/fractal-ome-zarr-examples/\"\n    \"refs/heads/main/v04/\"\n    \"20200812-CardiomyocyteDifferentiation14-Cycle1_B_03_mip.zarr/\"\n)\n\nfs = fsspec.implementations.http.HTTPFileSystem(client_kwargs={})\nstore = fs.get_mapper(url)\nomezarr = open_omezarr_container(store)\nomezarr\n</pre> import fsspec import fsspec.implementations.http  url = (     \"https://raw.githubusercontent.com/\"     \"fractal-analytics-platform/fractal-ome-zarr-examples/\"     \"refs/heads/main/v04/\"     \"20200812-CardiomyocyteDifferentiation14-Cycle1_B_03_mip.zarr/\" )  fs = fsspec.implementations.http.HTTPFileSystem(client_kwargs={}) store = fs.get_mapper(url) omezarr = open_omezarr_container(store) omezarr Out[13]: <pre>OmeZarrContainer(levels=4, labels=['nuclei'], #tables=4)</pre>"},{"location":"notebooks/basic_usage/#ome-zarr-image-exploration","title":"OME-Zarr Image Exploration\u00b6","text":"<p>In this notebook we will show how to use the 'OmeZarr Container' class to explore and manage an OME-NGFF image.</p> <p>For this example we will use a small example image that can be downloaded from the following link: example ome-zarr</p>"},{"location":"notebooks/basic_usage/#omezarr-container","title":"OmeZarr Container\u00b6","text":"<p>The <code>OmeZarr Container</code> provides a high-level interface to read, write and manipulate NGFF images. A <code>OmeZarr Container</code> can be created from a storelike object (e.g. a path to a directory, or a url) or from a <code>zarr.Group</code> object.</p>"},{"location":"notebooks/basic_usage/#labels","title":"Labels\u00b6","text":"<p>The <code>NgffImage</code> can also be used to load labels from a <code>OME-NGFF</code> file and behave similarly to the <code>Image</code> object.</p>"},{"location":"notebooks/basic_usage/#tables","title":"Tables\u00b6","text":"<p>The <code>NgffImage</code> can also be used to load tables from a <code>OME-NGFF</code> file.</p> <p><code>ngio</code> supports three types of tables:</p> <ul> <li><code>features table</code> A simple table to store features associated with a label.</li> <li><code>roi table</code> A table to store regions of interest.</li> <li><code>masking roi tables</code> A table to store single objects bounding boxes associated with a label.</li> </ul>"},{"location":"notebooks/basic_usage/#derive-a-new-ngffimage","title":"Derive a new NgffImage\u00b6","text":"<p>When processing an image, it is often useful to derive a new image from the original image. The <code>NgffImage</code> class provides a method to derive a new image from the original image. When deriving a new image, a new <code>NgffImage</code> object is created with the same metadata as the original image. Optionally the user can specify different metadata for the new image(.e.g. different channels names).</p>"},{"location":"notebooks/basic_usage/#create-an-omezarr-from-a-numpy-array","title":"Create an OmeZarr From a Numpy Array\u00b6","text":""},{"location":"notebooks/basic_usage/#steam-an-omezarr-over-http","title":"Steam an OmeZarr over HTTP\u00b6","text":"<p>The <code>OmeZarr</code> class can also be used to stream an image over HTTP. This is useful when the image is stored on a remote server and you want to access it without downloading the entire image. All features of the <code>OmeZarr</code> class are available when streaming an image over HTTP (besides anything that requires writing to the image).</p>"},{"location":"notebooks/basic_usage/#streaming-an-omezarr-from-a-fractal-server","title":"Streaming an OmeZarr from a Fractal Server\u00b6","text":"<p>Example:</p> <pre>from ngio.utils import fractal_fsspec_store\n\nstore = fractal_fsspec_store(url=\"https://fracral_url...\", fractal_token=\"**your_secret_token**\")\nomezarr = open_omezarr_container(store)\nomezarr\n</pre>"},{"location":"notebooks/image/","title":"Images/Labels/Tables","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport matplotlib.pyplot as plt\n\nfrom ngio import open_omezarr_container\nfrom ngio.utils import download_ome_zarr_dataset\n\n# Download the dataset\ndownload_dir = Path(\".\").absolute().parent.parent / \"data\"\nhcs_path = download_ome_zarr_dataset(\"CardiomyocyteSmallMip\", download_dir=download_dir)\nimage_path = hcs_path / \"B\" / \"03\" / \"0\"\n\n# Open the ome-zarr container\nomezarr = open_omezarr_container(image_path)\n</pre> from pathlib import Path  import matplotlib.pyplot as plt  from ngio import open_omezarr_container from ngio.utils import download_ome_zarr_dataset  # Download the dataset download_dir = Path(\".\").absolute().parent.parent / \"data\" hcs_path = download_ome_zarr_dataset(\"CardiomyocyteSmallMip\", download_dir=download_dir) image_path = hcs_path / \"B\" / \"03\" / \"0\"  # Open the ome-zarr container omezarr = open_omezarr_container(image_path) In\u00a0[2]: Copied! <pre>image = omezarr.get_image()\n\nprint(\"Image information:\")\nprint(f\"{image.shape=}\")\nprint(f\"{image.pixel_size=}\")\nprint(f\"{image.channel_labels=}\")\nprint(f\"{image.dimensions=}\")\n</pre> image = omezarr.get_image()  print(\"Image information:\") print(f\"{image.shape=}\") print(f\"{image.pixel_size=}\") print(f\"{image.channel_labels=}\") print(f\"{image.dimensions=}\") <pre>Image information:\nimage.shape=(3, 1, 4320, 5120)\nimage.pixel_size=PixelSize(x=0.1625, y=0.1625, z=1.0, t=1.0)\nimage.channel_labels=['DAPI', 'nanog', 'Lamin B1']\nimage.dimensions=Dimensions(c: 3, z: 1, y: 4320, x: 5120)\n</pre> <p>The <code>Image</code> object created is a lazy object, meaning that the image is not loaded into memory until it is needed. To get the image data from disk we can use the <code>.array</code> attribute or we can get it as a <code>dask.array</code> object using the <code>.dask_array</code> attribute.</p> In\u00a0[3]: Copied! <pre>image.get_array(mode=\"dask\")  # this call is lazy\n</pre> image.get_array(mode=\"dask\")  # this call is lazy Out[3]:  Array   Chunk   Bytes   126.56 MiB   10.55 MiB   Shape   (3, 1, 4320, 5120)   (1, 1, 2160, 2560)   Dask graph   12 chunks in 2 graph layers   Data type   uint16 numpy.ndarray  3 1 5120 4320 1 <p>Images can be queried for any axes, in any order</p> In\u00a0[4]: Copied! <pre>print(\"On disk shape: \", image.shape)\n\n# Axes order can be specified\n# if an axis is not present in the array, it will be added as a singleton dimension\narray = image.get_array(axes_order=[\"x\", \"t\", \"c\", \"y\", \"z\"], mode=\"dask\")\n\nprint(\"Array shape: \", array.shape)\n</pre> print(\"On disk shape: \", image.shape)  # Axes order can be specified # if an axis is not present in the array, it will be added as a singleton dimension array = image.get_array(axes_order=[\"x\", \"t\", \"c\", \"y\", \"z\"], mode=\"dask\")  print(\"Array shape: \", array.shape) <pre>On disk shape:  (3, 1, 4320, 5120)\nArray shape:  (5120, 1, 3, 4320, 1)\n</pre> In\u00a0[5]: Copied! <pre>roi_table = omezarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\")\n# Get a roi by name\nroi = roi_table.get(\"FOV_1\")\nprint(f\"{roi=}\")\n\n# .get_roi works exactly like .get_array\n# the only difference is that x, y, z, axes are queried from the roi object\nimage_roi_1 = image.get_roi(roi=roi, c=0, mode=\"dask\")\nimage_roi_1\n</pre> roi_table = omezarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\") # Get a roi by name roi = roi_table.get(\"FOV_1\") print(f\"{roi=}\")  # .get_roi works exactly like .get_array # the only difference is that x, y, z, axes are queried from the roi object image_roi_1 = image.get_roi(roi=roi, c=0, mode=\"dask\") image_roi_1 <pre>roi=WorldCooROI(name='FOV_1', x_length=416.0, y_length=351.0, z_length=1.0, x=0.0, y=0.0, z=0.0, x_micrometer_original=np.float32(-1448.3), y_micrometer_original=np.float32(-1517.7))\n</pre> Out[5]:  Array   Chunk   Bytes   10.55 MiB   10.55 MiB   Shape   (1, 1, 2160, 2560)   (1, 1, 2160, 2560)   Dask graph   1 chunks in 3 graph layers   Data type   uint16 numpy.ndarray  1 1 2560 2160 1 <p>The roi object can is defined in physical coordinates, and can be used to extract the region of interest from the image or label at any resolution.</p> In\u00a0[6]: Copied! <pre>image_2 = omezarr.get_image(path=\"2\")\n# Two images at different resolutions\nprint(f\"{image.pixel_size=}\")\nprint(f\"{image_2.pixel_size=}\")\n\n# Get roi for higher resolution image\nimage_1_roi_1 = image.get_roi(roi=roi, c=0, mode=\"dask\")\n\n# Get roi for lower resolution image\nimage_2_roi_1 = image_2.get_roi(roi=roi, c=0, mode=\"dask\")\n\n# Plot the two images side by side\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\naxs[0].imshow(image_1_roi_1[0, 0], cmap=\"gray\")\naxs[1].imshow(image_2_roi_1[0, 0], cmap=\"gray\")\nplt.show()\n</pre> image_2 = omezarr.get_image(path=\"2\") # Two images at different resolutions print(f\"{image.pixel_size=}\") print(f\"{image_2.pixel_size=}\")  # Get roi for higher resolution image image_1_roi_1 = image.get_roi(roi=roi, c=0, mode=\"dask\")  # Get roi for lower resolution image image_2_roi_1 = image_2.get_roi(roi=roi, c=0, mode=\"dask\")  # Plot the two images side by side fig, axs = plt.subplots(1, 2, figsize=(10, 5)) axs[0].imshow(image_1_roi_1[0, 0], cmap=\"gray\") axs[1].imshow(image_2_roi_1[0, 0], cmap=\"gray\") plt.show() <pre>image.pixel_size=PixelSize(x=0.1625, y=0.1625, z=1.0, t=1.0)\nimage_2.pixel_size=PixelSize(x=0.65, y=0.65, z=1.0, t=1.0)\n</pre> In\u00a0[7]: Copied! <pre>import numpy as np\n\n# Get a small slice of the image\nsmall_slice = image.get_array(x=slice(1000, 2000), y=slice(1000, 2000))\n\n# Set the sample slice to zeros\nzeros_slice = np.zeros_like(small_slice)\nimage.set_array(patch=zeros_slice, x=slice(1000, 2000), y=slice(1000, 2000))\n\n\n# Load the image from disk and show the edited image\nnuclei = omezarr.get_label(\"nuclei\", path=\"0\")\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\naxs[0].imshow(image.get_array()[0, 0], cmap=\"gray\")\naxs[1].imshow(nuclei.get_array()[0])\nfor ax in axs:\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n\n# Add back the original slice to the image\nimage.set_array(patch=small_slice, x=slice(1000, 2000), y=slice(1000, 2000))\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\naxs[0].imshow(image.get_array()[0, 0], cmap=\"gray\")\naxs[1].imshow(nuclei.get_array()[0])\nfor ax in axs:\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np  # Get a small slice of the image small_slice = image.get_array(x=slice(1000, 2000), y=slice(1000, 2000))  # Set the sample slice to zeros zeros_slice = np.zeros_like(small_slice) image.set_array(patch=zeros_slice, x=slice(1000, 2000), y=slice(1000, 2000))   # Load the image from disk and show the edited image nuclei = omezarr.get_label(\"nuclei\", path=\"0\") fig, axs = plt.subplots(1, 2, figsize=(10, 5))  axs[0].imshow(image.get_array()[0, 0], cmap=\"gray\") axs[1].imshow(nuclei.get_array()[0]) for ax in axs:     ax.axis(\"off\") plt.tight_layout() plt.show()  # Add back the original slice to the image image.set_array(patch=small_slice, x=slice(1000, 2000), y=slice(1000, 2000))  fig, axs = plt.subplots(1, 2, figsize=(10, 5)) axs[0].imshow(image.get_array()[0, 0], cmap=\"gray\") axs[1].imshow(nuclei.get_array()[0]) for ax in axs:     ax.axis(\"off\") plt.tight_layout() plt.show() In\u00a0[8]: Copied! <pre># Create a a new label object and set it to a simple segmentation\nnew_label = omezarr.derive_label(\"new_label\", overwrite=True)\n\nsimple_segmentation = image.get_array(c=0) &gt; 100\nsimple_segmentation = simple_segmentation[0]\nnew_label.set_array(simple_segmentation)\n\n# make a subplot with two image show side by side\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\naxs[0].imshow(image.get_array()[0, 0], cmap=\"gray\")\naxs[1].imshow(new_label.get_array()[0])\nfor ax in axs:\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n</pre> # Create a a new label object and set it to a simple segmentation new_label = omezarr.derive_label(\"new_label\", overwrite=True)  simple_segmentation = image.get_array(c=0) &gt; 100 simple_segmentation = simple_segmentation[0] new_label.set_array(simple_segmentation)  # make a subplot with two image show side by side fig, axs = plt.subplots(1, 2, figsize=(10, 5)) axs[0].imshow(image.get_array()[0, 0], cmap=\"gray\") axs[1].imshow(new_label.get_array()[0]) for ax in axs:     ax.axis(\"off\") plt.tight_layout() plt.show() In\u00a0[9]: Copied! <pre>label_0 = omezarr.get_label(\"new_label\", path=\"0\")\nlabel_2 = omezarr.get_label(\"new_label\", path=\"2\")\n\nlabel_before_consolidation = label_2.zarr_array[...]\n\n# Consolidate the label\nlabel_0.consolidate()\n\nlabel_after_consolidation = label_2.zarr_array[...]\n\n\n# make a subplot with two image show side by side\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\naxs[0].imshow(label_before_consolidation[0], cmap=\"gray\")\naxs[1].imshow(label_after_consolidation[0], cmap=\"gray\")\nfor ax in axs:\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n</pre> label_0 = omezarr.get_label(\"new_label\", path=\"0\") label_2 = omezarr.get_label(\"new_label\", path=\"2\")  label_before_consolidation = label_2.zarr_array[...]  # Consolidate the label label_0.consolidate()  label_after_consolidation = label_2.zarr_array[...]   # make a subplot with two image show side by side fig, axs = plt.subplots(1, 2, figsize=(10, 5)) axs[0].imshow(label_before_consolidation[0], cmap=\"gray\") axs[1].imshow(label_after_consolidation[0], cmap=\"gray\") for ax in axs:     ax.axis(\"off\") plt.tight_layout() plt.show() In\u00a0[10]: Copied! <pre>import numpy as np\nimport pandas as pd\n\nfrom ngio.tables import FeatureTable\n\nprint(f\"List of all tables: {omezarr.list_tables()}\")\n\n\nnuclei = omezarr.get_label(\"nuclei\", path=\"0\")\nroi_table = omezarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\")\n\n# Create a table with random features for each nuclei in each ROI\nlist_of_records = []\nfor roi in roi_table.rois():\n    nuclei_in_roi = nuclei.get_roi(roi, mode=\"numpy\")\n    for nuclei_id in np.unique(nuclei_in_roi)[1:]:\n        list_of_records.append(\n            {\n                \"label\": nuclei_id,\n                \"feat1\": np.random.rand(),\n                \"feat2\": np.random.rand(),\n                \"ROI\": roi.name,\n            }\n        )\n\nfeat_df = pd.DataFrame.from_records(list_of_records)\n\nfeat_table = FeatureTable(feat_df, reference_label=\"nuclei\")\n\nomezarr.add_table(\"new_feature_table\", feat_table, overwrite=True)\n</pre> import numpy as np import pandas as pd  from ngio.tables import FeatureTable  print(f\"List of all tables: {omezarr.list_tables()}\")   nuclei = omezarr.get_label(\"nuclei\", path=\"0\") roi_table = omezarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\")  # Create a table with random features for each nuclei in each ROI list_of_records = [] for roi in roi_table.rois():     nuclei_in_roi = nuclei.get_roi(roi, mode=\"numpy\")     for nuclei_id in np.unique(nuclei_in_roi)[1:]:         list_of_records.append(             {                 \"label\": nuclei_id,                 \"feat1\": np.random.rand(),                 \"feat2\": np.random.rand(),                 \"ROI\": roi.name,             }         )  feat_df = pd.DataFrame.from_records(list_of_records)  feat_table = FeatureTable(feat_df, reference_label=\"nuclei\")  omezarr.add_table(\"new_feature_table\", feat_table, overwrite=True) <pre>List of all tables: ['FOV_ROI_table', 'nuclei_ROI_table', 'well_ROI_table', 'regionprops_DAPI', 'nuclei_measurements_wf3', 'nuclei_measurements_wf4', 'nuclei_lamin_measurements_wf4']\n</pre> <pre>/opt/hostedtoolcache/Python/3.13.2/x64/lib/python3.13/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n  utils.warn_names_duplicates(\"obs\")\n</pre> In\u00a0[11]: Copied! <pre>feat_table = omezarr.get_table(\"new_feature_table\")\nfeat_table.dataframe\n</pre> feat_table = omezarr.get_table(\"new_feature_table\") feat_table.dataframe <pre>/opt/hostedtoolcache/Python/3.13.2/x64/lib/python3.13/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n  utils.warn_names_duplicates(\"obs\")\n</pre> Out[11]: feat1 feat2 ROI label 1 0.537110 0.441905 FOV_1 2 0.051252 0.795880 FOV_1 3 0.242205 0.268075 FOV_1 4 0.916818 0.476064 FOV_1 5 0.340103 0.271116 FOV_1 ... ... ... ... 2987 0.401431 0.233802 FOV_4 2991 0.152870 0.933200 FOV_4 2993 0.869746 0.568318 FOV_4 2995 0.135629 0.795852 FOV_4 2996 0.348884 0.158773 FOV_4 <p>3091 rows \u00d7 3 columns</p>"},{"location":"notebooks/image/#imageslabelstables","title":"Images/Labels/Tables\u00b6","text":"<p>In this notebook we will show how to use the <code>Image</code>, <code>Label</code> and <code>Table</code> objects to do image processing.</p>"},{"location":"notebooks/image/#images","title":"Images\u00b6","text":"<p>Images can be loaded from a <code>OmeZarrContainer</code> object.</p>"},{"location":"notebooks/image/#data-loading","title":"Data Loading\u00b6","text":""},{"location":"notebooks/image/#roitableimage-interaction","title":"RoiTable/Image Interaction\u00b6","text":"<p><code>roi</code> objects from a <code>roi_table</code> can be used to extract a region of interest from an image or a label.</p>"},{"location":"notebooks/image/#writing-images","title":"Writing Images\u00b6","text":"<p>Similarly to the <code>.array()</code>  we can use the <code>.set_array()</code> (or <code>set_array_from_roi</code>) method to write part of an image to disk.</p>"},{"location":"notebooks/image/#deriving-a-new-label","title":"Deriving a new label\u00b6","text":"<p>When doing image analysis, we often need to create new labels or tables. The <code>ngff_image</code> allows us to simply create new labels and tables.</p>"},{"location":"notebooks/image/#image-consolidation","title":"Image Consolidation\u00b6","text":"<p>Every time we modify a label or a image, we are modifying the on-disk data on one layer only. This means that if we have the image saved in multiple resolutions, we need to consolidate the changes to all resolutions. To do so, we can use the <code>.consolidate()</code> method.</p>"},{"location":"notebooks/image/#creating-a-new-table","title":"Creating a new table\u00b6","text":"<p>We can simply create a new table by create a new <code>Table</code> object from a pandas dataframe. For a simple feature table the only reuiremnt is to have a integer column named <code>label</code> that will be used to link the table to the objects in the image.</p>"},{"location":"notebooks/processing/","title":"Processing","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport matplotlib.pyplot as plt\n\nfrom ngio import open_omezarr_container\nfrom ngio.utils import download_ome_zarr_dataset\n\n# Download the dataset\ndownload_dir = Path(\".\").absolute().parent.parent / \"data\"\nhcs_path = download_ome_zarr_dataset(\"CardiomyocyteTiny\", download_dir=download_dir)\nimage_path = hcs_path / \"B\" / \"03\" / \"0\"\n\n# Open the ome-zarr container\nomezarr = open_omezarr_container(image_path)\n</pre> from pathlib import Path  import matplotlib.pyplot as plt  from ngio import open_omezarr_container from ngio.utils import download_ome_zarr_dataset  # Download the dataset download_dir = Path(\".\").absolute().parent.parent / \"data\" hcs_path = download_ome_zarr_dataset(\"CardiomyocyteTiny\", download_dir=download_dir) image_path = hcs_path / \"B\" / \"03\" / \"0\"  # Open the ome-zarr container omezarr = open_omezarr_container(image_path) <pre>Downloading data from 'https://zenodo.org/records/13305156/files/20200812-CardiomyocyteDifferentiation14-Cycle1.zarr.zip' to file '/home/runner/work/ngio/ngio/data/20200812-CardiomyocyteDifferentiation14-Cycle1.zarr.zip'.\n</pre> <pre>Unzipping contents of '/home/runner/work/ngio/ngio/data/20200812-CardiomyocyteDifferentiation14-Cycle1.zarr.zip' to '/home/runner/work/ngio/ngio/data/'\n</pre> In\u00a0[2]: Copied! <pre>mip_omezarr = omezarr.derive_image(\n    \"data/20200812-CardiomyocyteDifferentiation14-Cycle1.zarr/B/03/0_mip\",\n    shape=(1, 1, 2160, 5120),\n    overwrite=True,\n)\n</pre> mip_omezarr = omezarr.derive_image(     \"data/20200812-CardiomyocyteDifferentiation14-Cycle1.zarr/B/03/0_mip\",     shape=(1, 1, 2160, 5120),     overwrite=True, ) In\u00a0[3]: Copied! <pre># Get the source imag\nsource_image = omezarr.get_image()\nprint(\"Source image loaded with shape:\", source_image.shape)\n\n# Get the MIP image\nmip_image = mip_omezarr.get_image()\nprint(\"MIP image loaded with shape:\", mip_image.shape)\n\n# Get a ROI table\nroi_table = omezarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\")\nprint(\"ROI table loaded with\", len(roi_table.rois()), \"ROIs\")\n\n# For each ROI in the table\n# - get the data from the source image\n# - calculate the MIP\n# - set the data in the MIP image\nfor roi in roi_table.rois():\n    print(f\" - Processing ROI {roi.name}\")\n    patch = source_image.get_roi(roi)\n    mip_patch = patch.max(axis=1, keepdims=True)\n    mip_image.set_roi(patch=mip_patch, roi=roi)\n\nprint(\"MIP image saved\")\n\nplt.figure(figsize=(5, 5))\nplt.title(\"Mip\")\nplt.imshow(mip_image.zarr_array[0, 0, :, :], cmap=\"gray\")\nplt.axis(\"off\")\nplt.tight_layout()\nplt.show()\n</pre> # Get the source imag source_image = omezarr.get_image() print(\"Source image loaded with shape:\", source_image.shape)  # Get the MIP image mip_image = mip_omezarr.get_image() print(\"MIP image loaded with shape:\", mip_image.shape)  # Get a ROI table roi_table = omezarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\") print(\"ROI table loaded with\", len(roi_table.rois()), \"ROIs\")  # For each ROI in the table # - get the data from the source image # - calculate the MIP # - set the data in the MIP image for roi in roi_table.rois():     print(f\" - Processing ROI {roi.name}\")     patch = source_image.get_roi(roi)     mip_patch = patch.max(axis=1, keepdims=True)     mip_image.set_roi(patch=mip_patch, roi=roi)  print(\"MIP image saved\")  plt.figure(figsize=(5, 5)) plt.title(\"Mip\") plt.imshow(mip_image.zarr_array[0, 0, :, :], cmap=\"gray\") plt.axis(\"off\") plt.tight_layout() plt.show() <pre>Source image loaded with shape: (1, 2, 2160, 5120)\nMIP image loaded with shape: (1, 1, 2160, 5120)\nROI table loaded with 2 ROIs\n - Processing ROI FOV_1\n - Processing ROI FOV_2\nMIP image saved\n</pre> In\u00a0[4]: Copied! <pre># Get the MIP image at a lower resolution\nmip_image_2 = mip_omezarr.get_image(path=\"2\")\n\nimage_before_consolidation = mip_image_2.get_array(c=0, z=0)\n\n# Consolidate the pyramid\nmip_image.consolidate()\n\nimage_after_consolidation = mip_image_2.get_array(c=0, z=0)\n\nfig, axs = plt.subplots(2, 1, figsize=(10, 5))\naxs[0].set_title(\"Before consolidation\")\naxs[0].imshow(image_before_consolidation[0, 0], cmap=\"gray\")\naxs[1].set_title(\"After consolidation\")\naxs[1].imshow(image_after_consolidation[0, 0], cmap=\"gray\")\nfor ax in axs:\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n</pre> # Get the MIP image at a lower resolution mip_image_2 = mip_omezarr.get_image(path=\"2\")  image_before_consolidation = mip_image_2.get_array(c=0, z=0)  # Consolidate the pyramid mip_image.consolidate()  image_after_consolidation = mip_image_2.get_array(c=0, z=0)  fig, axs = plt.subplots(2, 1, figsize=(10, 5)) axs[0].set_title(\"Before consolidation\") axs[0].imshow(image_before_consolidation[0, 0], cmap=\"gray\") axs[1].set_title(\"After consolidation\") axs[1].imshow(image_after_consolidation[0, 0], cmap=\"gray\") for ax in axs:     ax.axis(\"off\") plt.tight_layout() plt.show() In\u00a0[5]: Copied! <pre>from ngio.tables import RoiTable\n\nroi_list = []\nfor roi in roi_table.rois():\n    print(f\" - Processing ROI {roi.name}\")\n    roi.z_length = 1  # In the MIP image, the z dimension is 1\n    roi_list.append(roi)\n\nmip_roi_table = RoiTable(rois=roi_list)\n\nmip_omezarr.add_table(\"FOV_ROI_table\", mip_roi_table)\n</pre> from ngio.tables import RoiTable  roi_list = [] for roi in roi_table.rois():     print(f\" - Processing ROI {roi.name}\")     roi.z_length = 1  # In the MIP image, the z dimension is 1     roi_list.append(roi)  mip_roi_table = RoiTable(rois=roi_list)  mip_omezarr.add_table(\"FOV_ROI_table\", mip_roi_table) <pre> - Processing ROI FOV_1\n - Processing ROI FOV_2\n</pre> In\u00a0[6]: Copied! <pre># Setup a simple segmentation function\n\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\nfrom skimage.filters import threshold_otsu\nfrom skimage.measure import label\n\nrand_cmap = np.random.rand(1000, 3)\nrand_cmap[0] = 0\nrand_cmap = ListedColormap(rand_cmap)\n\n\ndef otsu_threshold_segmentation(image: np.ndarray, max_label: int) -&gt; np.ndarray:\n    \"\"\"Simple segmentation using Otsu thresholding.\"\"\"\n    threshold = threshold_otsu(image)\n    binary = image &gt; threshold\n    label_image = label(binary)\n    label_image += max_label\n    label_image = np.where(binary, label_image, 0)\n    return label_image\n</pre> # Setup a simple segmentation function  import numpy as np from matplotlib.colors import ListedColormap from skimage.filters import threshold_otsu from skimage.measure import label  rand_cmap = np.random.rand(1000, 3) rand_cmap[0] = 0 rand_cmap = ListedColormap(rand_cmap)   def otsu_threshold_segmentation(image: np.ndarray, max_label: int) -&gt; np.ndarray:     \"\"\"Simple segmentation using Otsu thresholding.\"\"\"     threshold = threshold_otsu(image)     binary = image &gt; threshold     label_image = label(binary)     label_image += max_label     label_image = np.where(binary, label_image, 0)     return label_image In\u00a0[7]: Copied! <pre>nuclei_image = mip_omezarr.derive_label(name=\"nuclei\", overwrite=True)\n</pre> nuclei_image = mip_omezarr.derive_label(name=\"nuclei\", overwrite=True) In\u00a0[8]: Copied! <pre># Get the source imag\nsource_image = mip_omezarr.get_image()\nprint(\"Source image loaded with shape:\", source_image.shape)\n\n# Get a ROI table\nroi_table = mip_omezarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\")\nprint(\"ROI table loaded with\", len(roi_table.rois()), \"ROIs\")\n\n# Find the DAPI channel\ndapi_idx = source_image.channel_labels.index(\"DAPI\")\n\n# For each ROI in the table\n# - get the data from the source image\n# - calculate the Segmentation\n# - set the data in segmentation image\nmax_label = 0\nfor roi in roi_table.rois():\n    print(f\" - Processing ROI {roi.name}\")\n    patch = source_image.get_roi(roi, c=dapi_idx)\n    segmentation = otsu_threshold_segmentation(patch, max_label)\n\n    # Add the max label of the previous segmentation to avoid overlapping labels\n    segmentation = segmentation[0]\n    max_label = segmentation.max()\n\n    nuclei_image.set_roi(patch=segmentation, roi=roi)\n\n# Consolidate the segmentation image\nnuclei_image.consolidate()\n\nprint(\"Segmentation image saved\")\nfig, axs = plt.subplots(2, 1, figsize=(10, 5))\naxs[0].set_title(\"MIP\")\naxs[0].imshow(source_image.zarr_array[0, 0], cmap=\"gray\")\naxs[1].set_title(\"Nuclei segmentation\")\naxs[1].imshow(nuclei_image.zarr_array[0], cmap=rand_cmap, interpolation=\"nearest\")\nfor ax in axs:\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n</pre> # Get the source imag source_image = mip_omezarr.get_image() print(\"Source image loaded with shape:\", source_image.shape)  # Get a ROI table roi_table = mip_omezarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\") print(\"ROI table loaded with\", len(roi_table.rois()), \"ROIs\")  # Find the DAPI channel dapi_idx = source_image.channel_labels.index(\"DAPI\")  # For each ROI in the table # - get the data from the source image # - calculate the Segmentation # - set the data in segmentation image max_label = 0 for roi in roi_table.rois():     print(f\" - Processing ROI {roi.name}\")     patch = source_image.get_roi(roi, c=dapi_idx)     segmentation = otsu_threshold_segmentation(patch, max_label)      # Add the max label of the previous segmentation to avoid overlapping labels     segmentation = segmentation[0]     max_label = segmentation.max()      nuclei_image.set_roi(patch=segmentation, roi=roi)  # Consolidate the segmentation image nuclei_image.consolidate()  print(\"Segmentation image saved\") fig, axs = plt.subplots(2, 1, figsize=(10, 5)) axs[0].set_title(\"MIP\") axs[0].imshow(source_image.zarr_array[0, 0], cmap=\"gray\") axs[1].set_title(\"Nuclei segmentation\") axs[1].imshow(nuclei_image.zarr_array[0], cmap=rand_cmap, interpolation=\"nearest\") for ax in axs:     ax.axis(\"off\") plt.tight_layout() plt.show() <pre>Source image loaded with shape: (1, 1, 2160, 5120)\nROI table loaded with 2 ROIs\n - Processing ROI FOV_1\n - Processing ROI FOV_2\n</pre> <pre>Segmentation image saved\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/processing/#processing","title":"Processing\u00b6","text":"<p>In this notebook we will implement a couple of mock image analysis workflows using <code>ngio</code>.</p>"},{"location":"notebooks/processing/#maximum-intensity-projection","title":"Maximum intensity projection\u00b6","text":"<p>In this workflow we will read a volumetric image and create a maximum intensity projection (MIP) along the z-axis.</p>"},{"location":"notebooks/processing/#step-1-create-a-ngff-image","title":"step 1: Create a ngff image\u00b6","text":"<p>For this example we will use the following publicly available image</p>"},{"location":"notebooks/processing/#step-2-create-a-new-ngff-image-to-store-the-mip","title":"step 2: Create a new ngff image to store the MIP\u00b6","text":""},{"location":"notebooks/processing/#step-3-run-the-workflow","title":"step 3: Run the workflow\u00b6","text":"<p>For each roi in the image, create a MIP and store it in the new image</p>"},{"location":"notebooks/processing/#step-4-consolidate-the-results-important","title":"step 4: Consolidate the results (!!! Important)\u00b6","text":"<p>In this we wrote the mip image to a single level of the image pyramid. To truly consolidate the results we would need to write the mip to all levels of the image pyramid. We can do this by calling the <code>.consolidate()</code> method on the image.</p>"},{"location":"notebooks/processing/#step-5-create-a-new-roi-table","title":"step 5: Create a new ROI table\u00b6","text":"<p>As a final step we will create a new ROI table that contains the MIPs as ROIs. Where we correct the <code>z</code> bounds of the ROIs to reflect the MIP.</p>"},{"location":"notebooks/processing/#image-segmentation","title":"Image segmentation\u00b6","text":"<p>Now we can use the MIP image to segment the image using a simple thresholding algorithm.</p>"},{"location":"notebooks/processing/#step-1-derive-a-new-label-image-from-the-mip-image","title":"step 1: Derive a new label image from the MIP image\u00b6","text":""},{"location":"notebooks/processing/#step-2-run-the-workflow","title":"step 2: Run the workflow\u00b6","text":""}]}