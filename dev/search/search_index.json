{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NGIO: Streamlined OME-Zarr Image Analysis","text":"<p>ngio is a Python library designed to simplify bioimage analysis workflows, offering an intuitive interface for working with OME-Zarr files.</p>"},{"location":"#what-is-ngio","title":"What is Ngio?","text":"<p>Ngio is built for the OME-Zarr file format, a modern, cloud-optimized format for biological imaging data. OME-Zarr stores large, multi-dimensional microscopy images and metadata in an efficient and scalable way.</p> <p>Ngio's mission is to streamline working with OME-Zarr files by providing a simple, object-based API for opening, exploring, and manipulating OME-Zarr images and high-content screening (HCS) plates. It also offers comprehensive support for labels, tables and regions of interest (ROIs), making it easy to extract and analyze specific regions in your data.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#simple-object-based-api","title":"\ud83d\udcca Simple Object-Based API","text":"<ul> <li>Easily open, explore, and manipulate OME-Zarr images and HCS plates</li> <li>Create and derive new images and labels with minimal boilerplate code</li> </ul>"},{"location":"#rich-tables-and-regions-of-interest-roi-support","title":"\ud83d\udd0d Rich Tables and Regions of Interest (ROI) Support","text":"<ul> <li>Extract and analyze specific regions of interest</li> <li>Tight integration with Fractal's table framework</li> </ul>"},{"location":"#scalable-data-processing-coming-soon","title":"\ud83d\udd04 Scalable Data Processing (Coming Soon)","text":"<ul> <li>Powerful iterators for processing data at scale</li> <li>Efficient memory management for large datasets</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Refer to the Getting Started guide to integrate ngio into your workflows. We also provide a collection of Tutorials to help you get up and running quickly. For more advanced usage and API documentation, see our API Reference.</p>"},{"location":"#supported-ome-zarr-versions","title":"Supported OME-Zarr versions","text":"<p>Currently, ngio only supports OME-Zarr v0.4. Support for version 0.5 and higher is planned for future releases.</p>"},{"location":"#development-status","title":"Development Status","text":"<p>Warning</p> <p>Ngio is under active development and is not yet stable. The API is subject to change, and bugs and breaking changes are expected.</p>"},{"location":"#available-features","title":"Available Features","text":"<ul> <li>\u2705 OME-Zarr metadata handling and validation</li> <li>\u2705 Image and label access across pyramid levels</li> <li>\u2705 ROI and table support</li> <li>\u2705 Streaming from remote sources</li> <li>\u2705 Documentation and examples</li> </ul>"},{"location":"#upcoming-features","title":"Upcoming Features","text":"<ul> <li>Advanced image processing iterators</li> <li>Parallel processing capabilities</li> <li>Support for OME-Zarr v0.5 and Zarr v3</li> </ul>"},{"location":"#contributors","title":"Contributors","text":"<p>Ngio is developed at the BioVisionCenter, University of Zurich, by @lorenzocerrone and @jluethi.</p>"},{"location":"#license","title":"License","text":"<p>Ngio is released under the BSD-3-Clause License. See LICENSE for details.</p>"},{"location":"#repository","title":"Repository","text":"<p>Visit our GitHub repository for the latest code, issues, and contributions.</p>"},{"location":"code_of_conduct/","title":"Code of Conduct","text":"<p>Warning</p> <p>The library is still in the early stages of development, the code of conduct is not yet established.</p>"},{"location":"contributing/","title":"Contributing Guide","text":"<p>Warning</p> <p>The library is still in the early stages of development, no contribution guidelines are established yet. But contributions are welcome! Please open an issue or a pull request to discuss your ideas. We are looking for contributors to help us improve the library and documentation.</p>"},{"location":"api/common/","title":"ngio.common API documentation","text":"<p>Warning</p> <p>Coming soon, ngio API documentation is not yet available. If you have any questions please reach out to us on GitHub or via email. We are happy to help you with any questions or issues you may have.</p>"},{"location":"api/hcs/","title":"ngio.hcs API documentation","text":"<p>Warning</p> <p>Coming soon, ngio API documentation is not yet available. If you have any questions please reach out to us on GitHub or via email. We are happy to help you with any questions or issues you may have.</p>"},{"location":"api/images/","title":"ngio.images API documentation","text":"<p>Warning</p> <p>Coming soon, ngio API documentation is not yet available. If you have any questions please reach out to us on GitHub or via email. We are happy to help you with any questions or issues you may have.</p>"},{"location":"api/ngio/","title":"ngio API documentation","text":"<p>Warning</p> <p>Coming soon, ngio API documentation is not yet available. If you have any questions please reach out to us on GitHub or via email. We are happy to help you with any questions or issues you may have.</p>"},{"location":"api/tables/","title":"ngio.tables API documentation","text":"<p>Warning</p> <p>Coming soon, ngio API documentation is not yet available. If you have any questions please reach out to us on GitHub or via email. We are happy to help you with any questions or issues you may have.</p>"},{"location":"api/utils/","title":"ngio.utils","text":"<p>Warning</p> <p>Coming soon, ngio API documentation is not yet available. If you have any questions please reach out to us on GitHub or via email. We are happy to help you with any questions or issues you may have.</p>"},{"location":"getting_started/0_quickstart/","title":"Quickstart","text":"<p>Ngio is a Python package that provides a simple and intuitive API for reading and writing data to and from OME-Zarr. This guide will walk you through the basics of using <code>ngio</code> to read and write data.</p>"},{"location":"getting_started/0_quickstart/#installation","title":"Installation","text":"<p><code>ngio</code> can be installed from PyPI, conda-forge, or from source.</p> <ul> <li><code>ngio</code> requires Python <code>&gt;=3.11</code></li> </ul> pipmamba/condaSource <p>The recommended way to install <code>ngio</code> is from PyPI using pip:</p> <pre><code>pip install ngio\n</code></pre> <p>Alternatively, you can install <code>ngio</code> using mamba:</p> <pre><code>mamba install -c conda-forge ngio\n</code></pre> <p>or conda:</p> <pre><code>conda install -c conda-forge ngio\n</code></pre> <ol> <li> <p>Clone the repository: <pre><code>git clone https://github.com/fractal-analytics-platform/ngio.git\ncd ngio\n</code></pre></p> </li> <li> <p>Install the package: <pre><code>pip install .\n</code></pre></p> </li> </ol>"},{"location":"getting_started/0_quickstart/#troubleshooting","title":"Troubleshooting","text":"<p>Please report installation problems by opening an issue on our GitHub repository.</p>"},{"location":"getting_started/0_quickstart/#setup-some-test-data","title":"Setup some test data","text":"<p>Let's start by downloading a sample OME-Zarr dataset to work with.</p> <pre><code>from pathlib import Path\nfrom ngio.utils import download_ome_zarr_dataset\n\n# Download a sample dataset\ndownload_dir = Path(\"./data\")\nhcs_path = download_ome_zarr_dataset(\"CardiomyocyteSmallMip\", download_dir=download_dir)\nimage_path = hcs_path / \"B\" / \"03\" / \"0\"\n</code></pre>"},{"location":"getting_started/0_quickstart/#open-an-ome-zarr-image","title":"Open an OME-Zarr image","text":"<p>Let's start by opening an OME-Zarr file and inspecting its contents.</p> <pre><code>&gt;&gt;&gt; from ngio import open_ome_zarr_container\n&gt;&gt;&gt; ome_zarr_container = open_ome_zarr_container(image_path)\n&gt;&gt;&gt; ome_zarr_container\nOmeZarrContainer(levels=5, #labels=4, #tables=7)\n</code></pre>"},{"location":"getting_started/0_quickstart/#what-is-the-ome-zarr-container","title":"What is the OME-Zarr container?","text":"<p>The <code>OME-Zarr Container</code> is the core of ngio and the entry point to working with OME-Zarr images. It provides high-level access to the image metadata, images, labels, and tables.</p>"},{"location":"getting_started/0_quickstart/#what-is-the-ome-zarr-container-not","title":"What is the OME-Zarr container not?","text":"<p>The <code>OME-Zarr Container</code> object does not allow the user to interact with the image data directly. For that, we need to use the <code>Image</code>, <code>Label</code>, and <code>Table</code> objects.</p>"},{"location":"getting_started/0_quickstart/#next-steps","title":"Next steps","text":"<p>To learn how to work with the <code>OME-Zarr Container</code> object, but also with the image, label, and table data, check out the following guides:</p> <ul> <li>OME-Zarr Container: An overview on how to use the OME-Zarr Container object and how to create new images and labels.</li> <li>Images/Labels: To know more on how to work with image data.</li> <li>Tables: To know more on how to work with table data, and how you can combine tables with image data.</li> <li>Masked Images/Labels: To know more on how to work with masked image data.</li> <li>HCS Plates: To know more on how to work with HCS plate data.</li> </ul> <p>Also, checkout our jupyer notebook tutorials for more examples:</p> <ul> <li>Image Processing: Learn how to perform simple image processing operations.</li> <li>Image Segmentation: Learn how to create new labels from images.</li> <li>Feature Extraction: Learn how to extract features from images.</li> <li>HCS Processing: Learn how to process high-content screening data using ngio.</li> </ul>"},{"location":"getting_started/1_ome_zarr_containers/","title":"1. OME-Zarr Container","text":"<p>Let's see how to open and explore an OME-Zarr image using <code>ngio</code>:</p> <pre><code>from pathlib import Path\nfrom ngio import open_ome_zarr_container\nfrom ngio.utils import download_ome_zarr_dataset\n\n# Download a sample dataset\ndownload_dir = Path(\"./data\")\nhcs_path = download_ome_zarr_dataset(\"CardiomyocyteSmallMip\", download_dir=download_dir)\nimage_path = hcs_path / \"B\" / \"03\" / \"0\"\n\n# Open the OME-Zarr container\nome_zarr_container = open_ome_zarr_container(image_path)\n</code></pre> <p>The <code>OME-Zarr Container</code> in is your entry point to working with OME-Zarr images. It provides high-level access to the image metadata, images, labels, and tables.</p> <pre><code>&gt;&gt;&gt; ome_zarr_container\nOmeZarrContainer(levels=5, #labels=4, #tables=7)\n</code></pre> <p>The <code>OME-Zarr Container</code> will be the starting point for all your image processing tasks.</p>"},{"location":"getting_started/1_ome_zarr_containers/#main-concepts","title":"Main concepts","text":""},{"location":"getting_started/1_ome_zarr_containers/#what-is-the-ome-zarr-container","title":"What is the OME-Zarr container?","text":"<p>The <code>OME-Zarr Container</code> in ngio is your entry point to working with OME-Zarr images.</p> <p>It provides:</p> <ul> <li>OME-Zarr overview: get an overview of the OME-Zarr file, including the number of image levels, list of labels, and tables available.</li> <li>Image access: get access to the images at different resolution levels and pixel sizes.</li> <li>Label management: check which labels are available, access them, and create new labels.</li> <li>Table management: check which tables are available, access them, and create new tables.</li> <li>Derive new OME-Zarr images: create new images based on the original one, with the same or similar metadata.</li> </ul>"},{"location":"getting_started/1_ome_zarr_containers/#what-is-the-ome-zarr-container-not","title":"What is the OME-Zarr container not?","text":"<p>The <code>OME-Zarr Container</code> object does not allow the user to interact with the image data directly. For that, we need to use the <code>Image</code>, <code>Label</code>, and <code>Table</code> objects.</p>"},{"location":"getting_started/1_ome_zarr_containers/#ome-zarr-overview","title":"OME-Zarr overview","text":"<p>Examples of the OME-Zarr metadata access:</p> Number of Resolution LevelsAvailable PathsDimensionalityFull Metadata Object <p>Show the number of resolution levels: <pre><code>&gt;&gt;&gt; ome_zarr_container.levels # Show the number of resolution levels\n5\n</code></pre></p> <p>Show the paths to all available resolution levels: <pre><code>&gt;&gt;&gt; ome_zarr_container.levels_paths # Show the paths to all available images\n['0', '1', '2', '3', '4']\n</code></pre></p> <p>Show if the image is 2D or 3D: <pre><code>&gt;&gt;&gt; ome_zarr_container.is_3d # Get if the image is 3D\nFalse\n</code></pre> or if the image is a time series: <pre><code>&gt;&gt;&gt; ome_zarr_container.is_time_series # Get if the image is a time series\nFalse\n</code></pre></p> <p><pre><code>&gt;&gt;&gt; metadata = ome_zarr_container.image_meta\nNgioImageMeta(name=None, datasets=['0', '1', '2', '3', '4'], axes=['c', 'z', 'y', 'x'])\n</code></pre> The metadata object contains all the information about the image, for example, the channel labels: <pre><code>&gt;&gt;&gt; metadata.channel_labels\n['DAPI', 'nanog', 'Lamin B1']\n</code></pre></p>"},{"location":"getting_started/1_ome_zarr_containers/#accessing-images-labels-tables","title":"Accessing images / labels / tables","text":"<p>To access images, labels, and tables, you can use the <code>get_image</code>, <code>get_label</code>, and <code>get_table</code> methods of the <code>OME-Zarr Container</code> object.</p> <p>A variety of examples and additional information can be found in the Images and Labels, and Tables sections.</p>"},{"location":"getting_started/1_ome_zarr_containers/#creating-derived-images","title":"Creating derived images","text":"<p>When processing an image, you might want to create a new image with the same metadata:</p> <pre><code># Create a new image based on the original\nnew_image = ome_zarr_container.derive_image(\"data/new_ome.zarr\", overwrite=True)\n</code></pre> <p>This will create a new OME-Zarr image with the same metadata as the original image. But you can also create a new image with slightly different metadata, for example, with a different shape:</p> <pre><code># Create a new image with a different shape\nnew_image = ome_zarr_container.derive_image(\n    \"data/new_ome.zarr\", \n    overwrite=True, \n    shape=(16, 128, 128), \n    xy_pixelsize=0.65, \n    z_spacing=1.0\n)\n</code></pre>"},{"location":"getting_started/1_ome_zarr_containers/#creating-new-images","title":"Creating new images","text":"<p>You can create OME-Zarr images from an existing numpy array using the <code>create_ome_zarr_from_array</code> function.</p> <pre><code>import numpy as np\nfrom ngio import create_ome_zarr_from_array\n\n# Create a random 3D array\nx = np.random.randint(0, 255, (16, 128, 128), dtype=np.uint8)\n\n# Save as OME-Zarr\nnew_ome_zarr_image = create_ome_zarr_from_array(\n    store=\"random_ome.zarr\", \n    array=x, \n    xy_pixelsize=0.65, \n    z_spacing=1.0\n)\n</code></pre> <p>Alternatively, if you wanto to create an a empty OME-Zarr image, you can use the <code>create_empty_ome_zarr</code> function:</p> <pre><code>from ngio import create_empty_ome_zarr\n# Create an empty OME-Zarr image\nnew_ome_zarr_image = create_empty_ome_zarr(\n    store=\"empty_ome.zarr\", \n    shape=(16, 128, 128), \n    xy_pixelsize=0.65, \n    z_spacing=1.0\n)\n</code></pre> <p>This will create an empty OME-Zarr image with the specified shape and pixel sizes.</p>"},{"location":"getting_started/1_ome_zarr_containers/#opening-remote-ome-zarr-containers","title":"Opening remote OME-Zarr containers","text":"<p>You can use <code>ngio</code> to open remote OME-Zarr containers. For publicly available OME-Zarr containers, you can just use the <code>open_ome_zarr_container</code> function with a URL.</p> <p>For example, to open a remote OME-Zarr container hosted on a github repository:</p> <pre><code>from ngio.utils import fractal_fsspec_store\n\nurl = (\n    \"https://raw.githubusercontent.com/\"\n    \"fractal-analytics-platform/fractal-ome-zarr-examples/\"\n    \"refs/heads/main/v04/\"\n    \"20200812-CardiomyocyteDifferentiation14-Cycle1_B_03_mip.zarr/\"\n)\n\nstore = fractal_fsspec_store(url=url)\nome_zarr_container = open_ome_zarr_container(store)\n</code></pre> <p>For fractal users, the <code>fractal_fsspec_store</code> function can be used to open private OME-Zarr containers. In this case we need to provide a <code>fractal_token</code> to authenticate the user.</p> <pre><code>from ngio.utils import fractal_fsspec_store\n\nstore = fractal_fsspec_store(url=\"https://fractal_url...\", fractal_token=\"**your_secret_token**\")\nome_zarr_container = open_ome_zarr_container(store)\n</code></pre>"},{"location":"getting_started/2_images/","title":"2. Images and Labels","text":""},{"location":"getting_started/2_images/#images","title":"Images","text":"<p>In order to start working with the image data, we need to instantiate an <code>Image</code> object. ngio provides a high-level API to access the image data at different resolution levels and pixel sizes.</p>"},{"location":"getting_started/2_images/#getting-an-image","title":"Getting an image","text":"Highest Resolution ImageSpecific Pyramid LevelSpecific ResolutionNearest Resolution <p>By default, the <code>get_image</code> method returns the highest resolution image: <pre><code>&gt;&gt;&gt; ome_zarr_container.get_image() # Get the highest resolution image\nImage(path=0, Dimensions(c: 3, z: 1, y: 4320, x: 5120))\n</code></pre></p> <p>To get a specific pyramid level, you can use the <code>path</code> parameter: <pre><code>&gt;&gt;&gt; ome_zarr_container.get_image(path=\"1\") # Get a specific pyramid level\nImage(path=1, Dimensions(c: 3, z: 1, y: 2160, x: 2560))\n</code></pre> This will return the image at the specified pyramid level.</p> <p>If you want to get an image with a specific pixel size, you can use the <code>pixel_size</code> parameter: <pre><code>&gt;&gt;&gt; from ngio import PixelSize\n&gt;&gt;&gt; pixel_size = PixelSize(x=0.65, y=0.65, z=1.0)\n&gt;&gt;&gt; ome_zarr_container.get_image(pixel_size=pixel_size)\nImage(path=2, Dimensions(c: 3, z: 1, y: 1080, x: 1280))\n</code></pre></p> <p>By default the pixels must match exactly the requested pixel size. If you want to get the nearest resolution, you can use the <code>strict</code> parameter: <pre><code>&gt;&gt;&gt; from ngio import PixelSize\n&gt;&gt;&gt; pixel_size = PixelSize(x=0.60, y=0.60, z=1.0)\n&gt;&gt;&gt; ome_zarr_container.get_image(pixel_size=pixel_size, strict=False)\nImage(path=2, Dimensions(c: 3, z: 1, y: 1080, x: 1280))\n</code></pre> This will return the image with the nearest resolution to the requested pixel size.</p> <p>Similarly to the <code>OME-Zarr Container</code>, the <code>Image</code> object provides a high-level API to access the image metadata.</p> DimensionsPixel SizeOn disk array infos <p><pre><code>&gt;&gt;&gt; image.dimensions\nDimensions(c: 3, z: 1, y: 1080, x: 1280)\n</code></pre> The <code>dimensions</code> attribute returns a object with the image dimensions for each axis.</p> <p><pre><code>&gt;&gt;&gt; image.pixel_size\nPixelSize(x=0.65, y=0.65, z=1.0, t=1.0)\n</code></pre> The <code>pixel_size</code> attribute returns the pixel size for each axis.</p> <p><pre><code>&gt;&gt;&gt; image.shape, image.dtype, image.chunks\n(3, 1, 1080, 1280) uint16 (1, 1, 1080, 1280)\n</code></pre> The <code>axes</code> attribute returns the order of the axes in the image.</p>"},{"location":"getting_started/2_images/#working-with-image-data","title":"Working with image data","text":"<p>Once you have the <code>Image</code> object, you can access the image data as a:</p> Numpy ArrayDask ArrayDask Delayed <pre><code>&gt;&gt;&gt; data = image.get_array() # Get the image as a numpy array\n&gt;&gt;&gt; data.shape, data.dtype\n(3, 1, 1080, 1280) uint16\n</code></pre> <pre><code>&gt;&gt;&gt; dask_array = image.get_array(mode=\"dask\") # Get the image as a dask array\n&gt;&gt;&gt; dask_array\ndask.array&lt;from-zarr, shape=(3, 1, 1080, 1280), dtype=uint16, chunksize=(1, 1, 1080, 1280), chunktype=numpy.ndarray&gt;\n</code></pre> <pre><code>&gt;&gt;&gt; dask_delayed = image.get_array(mode=\"delayed\") # Get the image as a dask delayed object\n&gt;&gt;&gt; dask_delayed\nDelayed('transform_numpy_array-9f385ed2-fd52-4b23-8b4d-430ed0d3ef0e')\n</code></pre> <p>The <code>get_array</code> can also be used to slice the image data, and query specific axes in specific orders:</p> <pre><code>&gt;&gt;&gt; image_slice = image.get_array(c=0, x=slice(0, 128), axes_order=[\"t\", \"z\", \"y\", \"x\", \"c\"]) # Get a specific channel and axes order\n&gt;&gt;&gt; image_slice.shape\n(1, 1, 1080, 128, 1)\n</code></pre> <p>If you want to edit the image data, you can use the <code>set_array</code> method:</p> <pre><code>&gt;&gt;&gt; image.set_array(data) # Set the image data\n</code></pre> <p>The <code>set_array</code> method can be used to set the image data from a numpy array, dask array, or dask delayed object.</p> <p>A minimal example of how to use the <code>get_array</code> and <code>set_array</code> methods:</p> <pre><code># Get the image data as a numpy array\ndata = image.get_array(c=0, x=slice(0, 128), y=slice(0, 128), axes_order=[\"z\", \"y\", \"x\", \"c\"])\n\n# Modify the image data\ndata = some_function(data)\n\n# Set the modified image data\nimage.set_array(data, c=0, x=slice(0, 128), y=slice(0, 128), axes_order=[\"z\", \"y\", \"x\", \"c\"])\nimage.consolidate() # Consolidate the changes to all resolution levels, see below for more details\n</code></pre> <p>Important</p> <p>The <code>set_array</code> method will overwrite the image data at single resolution level. After you have finished editing the image data, you need to <code>consolidate</code> the changes to the OME-Zarr file at all resolution levels: <pre><code>&gt;&gt;&gt; image.consolidate() # Consolidate the changes\n</code></pre> This will write the changes to the OME-Zarr file at all resolution levels.</p>"},{"location":"getting_started/2_images/#labels","title":"Labels","text":"<p><code>Labels</code> represent segmentation masks that identify objects in the image. In ngio <code>Labels</code> are similar to <code>Images</code> and can be accessed and manipulated in the same way.</p>"},{"location":"getting_started/2_images/#getting-a-label","title":"Getting a label","text":"<p>Now let's see what labels are available in our image:</p> <pre><code>&gt;&gt;&gt; ome_zarr_container.list_labels() # Available labels\n['nuclei', 'wf_2_labels', 'wf_3_labels', 'wf_4_labels']\n</code></pre> <p>We have <code>4</code> labels available in our image. Let's see how to access them:</p> Highest Resolution LabelSpecific Pyramid LevelSpecific ResolutionNearest Resolution <p>By default, the <code>get_label</code> method returns the highest resolution label: <pre><code>&gt;&gt;&gt; ome_zarr_container.get_label(\"nuclei\") # Get the highest resolution label\nLabel(path=0, Dimensions(z: 1, y: 4320, x: 5120))\n</code></pre></p> <p>To get a specific pyramid level, you can use the <code>path</code> parameter: <pre><code>&gt;&gt;&gt; ome_zarr_container.get_label(\"nuclei\", path=\"1\") # Get a specific pyramid level\nLabel(path=1, Dimensions(z: 1, y: 2160, x: 2560))\n</code></pre> This will return the label at the specified pyramid level.</p> <p>If you want to get a label with a specific pixel size, you can use the <code>pixel_size</code> parameter: <pre><code>&gt;&gt;&gt; from ngio import PixelSize\n&gt;&gt;&gt; pixel_size = PixelSize(x=0.65, y=0.65, z=1.0)\n&gt;&gt;&gt; ome_zarr_container.get_label(\"nuclei\", pixel_size=pixel_size)\nLabel(path=2, Dimensions(z: 1, y: 1080, x: 1280))\n</code></pre></p> <p>By default the pixels must match exactly the requested pixel size. If you want to get the nearest resolution, you can use the <code>strict</code> parameter: <pre><code>&gt;&gt;&gt; from ngio import PixelSize\n&gt;&gt;&gt; pixel_size = PixelSize(x=0.60, y=0.60, z=1.0)\n&gt;&gt;&gt; ome_zarr_container.get_label(\"nuclei\", pixel_size=pixel_size, strict=False)\nLabel(path=2, Dimensions(z: 1, y: 1080, x: 1280))\n</code></pre> This will return the label with the nearest resolution to the requested pixel size.</p>"},{"location":"getting_started/2_images/#working-with-label-data","title":"Working with label data","text":"<p>Data access and manipulation for <code>Labels</code> is similar to <code>Images</code>. You can use the <code>get_array</code> and <code>set_array</code> methods to access and modify the label data.</p>"},{"location":"getting_started/2_images/#deriving-a-label","title":"Deriving a label","text":"<p>Often, you might want to create a new label based on an existing image. You can do this using the <code>derive_label</code> method:</p> <pre><code>&gt;&gt;&gt; new_label = ome_zarr_container.derive_label(\"new_label\", overwrite=True) # Derive a new label\nLabel(path=0, Dimensions(z: 1, y: 4320, x: 5120))\n</code></pre> <p>This will create a new label with the same dimensions as the original image (without channels) and compatible metadata. If you want to create a new label with slightly different metadata see API Reference.</p>"},{"location":"getting_started/3_tables/","title":"3. Tables","text":"<p>Tables are not part of the core OME-Zarr specification but can be used in ngio to store measurements, features, regions of interest (ROIs), and other tabular data. Ngio follows the Fractal's Table Spec.</p>"},{"location":"getting_started/3_tables/#getting-a-table","title":"Getting a table","text":"<p>We can list all available tables and load a specific table:</p> <pre><code>&gt;&gt;&gt; ome_zarr_container.list_tables()\n['FOV_ROI_table', 'nuclei_ROI_table', 'well_ROI_table', 'regionprops_DAPI', 'nuclei_measurements_wf3', 'nuclei_measurements_wf4', 'nuclei_lamin_measurements_wf4']\n</code></pre> <p>Ngio supports three types of tables: <code>roi_table</code>, <code>feature_table</code>, and <code>masking_roi_table</code>, as well as untyped <code>generic_table</code>.</p> ROI TableMasking ROI TableFeatures Table <p>ROI tables can be used to store arbitrary regions of interest (ROIs) in the image. Here for example we will load the <code>FOV_ROI_table</code> that contains the microscope field of view (FOV) ROIs: <pre><code>&gt;&gt;&gt; roi_table = ome_zarr_container.get_table(\"FOV_ROI_table\") # Get a ROI table\n&gt;&gt;&gt; roi_table.get(\"FOV_1\")\nname='FOV_1' x_length=416.0 y_length=351.0 z_length=1.0 x=0.0 y=0.0 z=0.0 y_micrometer_original=-1517.699951171875 x_micrometer_original=-1448.300048828125\n</code></pre> 2025-05-22T13:11:00.194377 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/    This will return all the ROIs in the table. ROIs can be used to slice the image data: <pre><code>&gt;&gt;&gt; roi = roi_table.get(\"FOV_1\")\n&gt;&gt;&gt; roi_data = image.get_roi(roi)\n&gt;&gt;&gt; roi_data.shape\n(3, 1, 540, 640)\n</code></pre> This will return the image data for the specified ROI.  2025-05-22T13:11:00.353510 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ </p> <p>Masking ROIs are a special type of ROIs that can be used to store ROIs for masked objects in the image. The <code>nuclei_ROI_table</code> contains the masks for the <code>nuclei</code> label in the image, and is indexed by the label id. <pre><code>&gt;&gt;&gt; masking_table = ome_zarr_container.get_table(\"nuclei_ROI_table\") # Get a mask table\n&gt;&gt;&gt; masking_table.get(1)\nname='100' x_length=11.375 y_length=14.625 z_length=1.0 x=33.63750076293945 y=18.850000381469727 z=0.0\n</code></pre> ROIs can be used to slice the image data: <pre><code>&gt;&gt;&gt; roi = masking_table.get(100)\n&gt;&gt;&gt; roi_data = image.get_roi(roi)\n&gt;&gt;&gt; roi_data.shape\n(3, 1, 22, 18)\n</code></pre> This will return the image data for the specified ROI.  2025-05-22T13:11:00.538147 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/    See 4. Masked Images and Labels for more details on how to use the masking ROIs to load masked data.</p> <p>Features tables are used to store measurements and are indexed by the label id <pre><code>&gt;&gt;&gt; feature_table = ome_zarr_container.get_table(\"regionprops_DAPI\") # Get a feature table\n&gt;&gt;&gt; feature_table.dataframe.head(5) # only show the first 5 rows\n</code></pre> label area bbox_area equivalent_diameter max_intensity mean_intensity min_intensity standard_deviation_intensity 1 2120 2655 15.9384 476 278.636 86 54.3438 2 327 456 8.54771 604 324.162 118 90.8471 3 1381 1749 13.8165 386 212.682 60 50.1696 4 2566 3588 16.9858 497 251.731 61 53.3072 5 4201 5472 20.0194 466 223.863 51 56.719 </p>"},{"location":"getting_started/3_tables/#creating-a-table","title":"Creating a table","text":"<p>Tables (differently from Images and Labels) can be purely in memory objects, and don't need to be saved on disk.</p> Creating a ROI TableCreating a Masking ROI TableCreating a Feature TableCreating a Generic Table <p><pre><code>&gt;&gt;&gt; from ngio.tables import RoiTable\n&gt;&gt;&gt; from ngio import Roi\n&gt;&gt;&gt; roi = Roi(x=0, y=0, x_length=128, y_length=128, name=\"FOV_1\")\n&gt;&gt;&gt; roi_table = RoiTable(rois=[roi])\nRoiTableV1(num_rois=1)\n</code></pre> If you would like to create on-the-fly a ROI table for the whole image: <pre><code>&gt;&gt;&gt; roi_table = ome_zarr_container.build_image_roi_table(\"whole_image\")\n&gt;&gt;&gt; roi_table\nRoiTableV1(num_rois=1)\n</code></pre> The <code>build_image_roi_table</code> method will create a ROI table with a single ROI that covers the whole image. This table is not associated with the image and is purely in memory. If we want to save it to disk, we can use the <code>add_table</code> method: <pre><code>&gt;&gt;&gt; ome_zarr_container.add_table(\"new_roi_table\", roi_table, overwrite=True)\n&gt;&gt;&gt; roi_table = ome_zarr_container.get_table(\"new_roi_table\")\nRoiTableV1(num_rois=1)\n</code></pre></p> <p>Similarly to the ROI table, we can create a masking ROI table on-the-fly: Let's for example create a masking ROI table for the <code>nuclei</code> label: <pre><code>&gt;&gt;&gt; masking_table = ome_zarr_container.build_masking_roi_table(\"nuclei\")\n&gt;&gt;&gt; masking_table\nMaskingRoiTableV1(num_rois=3006, reference_label=nuclei)\n</code></pre></p> <p>Feature tables can be created from a pandas <code>Dataframe</code>: <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"&lt;code block: session get_started; n40&gt;\", line 4, in &lt;module&gt;\n    feature_table = FeatureTable(dataframe=example_data)\nTypeError: FeatureTableV1.__init__() got an unexpected keyword argument 'dataframe'\n</code></pre></p> <p>Sometimes you might want to create a table that doesn't fit into the <code>ROI</code>, <code>Masking ROI</code>, or <code>Feature</code> categories. In this case, you can use the <code>GenericTable</code> class, which allows you to store any tabular data. It can be created from a pandas <code>Dataframe</code>: <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"&lt;code block: session get_started; n41&gt;\", line 4, in &lt;module&gt;\n    generic_table = GenericTable(dataframe=example_data)\nTypeError: AbstractBaseTable.__init__() got an unexpected keyword argument 'dataframe'\n</code></pre> Or from an \"AnnData\" object: <pre><code>Traceback (most recent call last):\n  File \"/opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/markdown_exec/_internal/formatters/python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/hostedtoolcache/Python/3.13.3/x64/lib/python3.13/site-packages/markdown_exec/_internal/formatters/_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"&lt;code block: session get_started; n42&gt;\", line 4, in &lt;module&gt;\n    generic_table = GenericTable(anndata=adata)\nTypeError: AbstractBaseTable.__init__() got an unexpected keyword argument 'anndata'\n</code></pre> The <code>GenericTable</code> class allows you to store any tabular data, and is a flexible way to work with tables in ngio.</p>"},{"location":"getting_started/4_masked_images/","title":"4. Masked Images and Labels","text":"<p>Masked images (or labels) are images that are masked by an instance segmentation mask.</p> <p>In this section we will show how to create a <code>MaskedImage</code> object and how to use it to get the data of the image.</p> <p></p> <p>Similar to the <code>Image</code> and <code>Label</code> objects, the <code>MaskedImage</code> can be initialized from an <code>OME-Zarr Container</code> object using the <code>get_masked_image</code> method.</p> <p>Let's create a masked image from the <code>nuclei</code> label:</p> <pre><code>&gt;&gt;&gt; masked_image = ome_zarr_container.get_masked_image(\"nuclei\")\n&gt;&gt;&gt; masked_image\nMaskedImage(path=0, Dimensions(c: 3, z: 1, y: 4320, x: 5120), nuclei)\n</code></pre> <p>Since the <code>MaskedImage</code> is a subclass of <code>Image</code>, we can use all the methods available for <code>Image</code> objects.</p> <p>The two most notable exceptions are the <code>get_roi</code> and <code>set_roi</code> which now instead of requiring a <code>roi</code> object, require an integer <code>label</code>.</p> <pre><code>&gt;&gt;&gt; roi_data = masked_image.get_roi(label=1009, c=0)\n&gt;&gt;&gt; roi_data.shape\n(1, 1, 76, 83)\n</code></pre> 2025-05-22T13:11:01.236158 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>Additionally we can used the <code>zoom_factor</code> argument to get more context around the ROI. For example we can zoom out the ROI by a factor of <code>2</code>:</p> <pre><code>&gt;&gt;&gt; roi_data = masked_image.get_roi(label=1009, c=0, zoom_factor=2)\n&gt;&gt;&gt; roi_data.shape\n(1, 1, 152, 166)\n</code></pre> 2025-05-22T13:11:01.300399 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"getting_started/4_masked_images/#masked-operations","title":"Masked operations","text":"<p>In addition to the <code>get_roi</code> method, the <code>MaskedImage</code> class also provides a masked operation method that allows you to perform reading and writing only on the masked pixels.</p> <p>For these operations we can use the <code>get_roi_masked</code> and <code>set_roi_masked</code> methods. For example, we can use the <code>get_roi_masked</code> method to get the masked data for a specific label:</p> <pre><code>&gt;&gt;&gt; masked_roi_data = masked_image.get_roi_masked(label=1009, c=0, zoom_factor=2)\n&gt;&gt;&gt; masked_roi_data.shape\n(1, 1, 152, 166)\n</code></pre> 2025-05-22T13:11:01.395478 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>We can also use the <code>set_roi_masked</code> method to set the masked data for a specific label:</p> <pre><code>&gt;&gt;&gt; masked_data = masked_image.get_roi_masked(label=1009, c=0)\n&gt;&gt;&gt; masked_data = np.random.randint(0, 255, masked_data.shape, dtype=np.uint8)\n&gt;&gt;&gt; masked_image.set_roi_masked(label=1009, c=0, patch=masked_data)\n</code></pre> 2025-05-22T13:11:01.493514 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"getting_started/4_masked_images/#masked-labels","title":"Masked Labels","text":"<p>The <code>MaskedLabel</code> class is a subclass of <code>Label</code> and provides the same functionality as the <code>MaskedImage</code> class.</p> <p>The <code>MaskedLabel</code> class can be used to create a masked label from an <code>OME-Zarr Container</code> object using the <code>get_masked_label</code> method.</p> <pre><code>&gt;&gt;&gt; masked_label = ome_zarr_container.get_masked_label(label_name = \"wf_2_labels\", masking_label_name = \"nuclei\")\n&gt;&gt;&gt; masked_label\nMaskedLabel(path=0, Dimensions(z: 1, y: 4320, x: 5120), nuclei)\n</code></pre>"},{"location":"getting_started/5_hcs/","title":"5. HCS Plates","text":"<p>Ngio provides a simple interface for high-content screening (HCS) plates. An HCS plate is a collection of OME-Zarr images organized in a grid-like structure. Each plates contains columns and rows, and each well in the plate is identified by its row and column indices. Each well can contain multiple images, and each image can belong to a different acquisition.</p> <p>The HCS plate is represented by the <code>OmeZarrPlate</code> class.</p> <p>Let's open an <code>OmeZarrPlate</code> object.</p> <pre><code>&gt;&gt;&gt; from ngio.utils import download_ome_zarr_dataset\n&gt;&gt;&gt; from ngio import open_ome_zarr_plate\n&gt;&gt;&gt; hcs_path = download_ome_zarr_dataset(\"CardiomyocyteSmallMip\", download_dir=download_dir)\n&gt;&gt;&gt; ome_zarr_plate = open_ome_zarr_plate(hcs_path)\n&gt;&gt;&gt; ome_zarr_plate\nPlate([rows x columns] (1 x 1))\n</code></pre> <p>This example plate is very small and contains only a single well.</p>"},{"location":"getting_started/5_hcs/#plate-overview","title":"Plate overview","text":"<p>The <code>OmeZarrPlate</code> object provides a high-level overview of the plate, including rows, columns, and acquisitions. The following methods are available:</p> ColumnsRowsAcquisitions <p>Show the columns in the plate: <pre><code>&gt;&gt;&gt; ome_zarr_plate.columns\n['03']\n</code></pre></p> <p>Show the rows in the plate: <pre><code>&gt;&gt;&gt; ome_zarr_plate.rows\n['B']\n</code></pre></p> <p>Show the acquisitions ids: <pre><code>&gt;&gt;&gt; ome_zarr_plate.acquisition_ids\n[0]\n</code></pre></p>"},{"location":"getting_started/5_hcs/#retrieving-the-path-to-the-images","title":"Retrieving the path to the images","text":"<p>The <code>OmeZarrPlate</code> object provides multiple methods to retrieve the path to the images in the plate.</p> All Images PathsAll Wells PathsAll Images Paths in a Well <p>This will return the paths to all images in the plate: <pre><code>&gt;&gt;&gt; ome_zarr_plate.images_paths()\n['B/03/0']\n</code></pre></p> <p>This will return the paths to all wells in the plate: <pre><code>&gt;&gt;&gt; ome_zarr_plate.wells_paths()\n['B/03']\n</code></pre></p> <p>This will return the paths to all images in a well: <pre><code>&gt;&gt;&gt; ome_zarr_plate.well_images_paths(row=\"B\", column=3)\n['B/03/0']\n</code></pre></p>"},{"location":"getting_started/5_hcs/#getting-the-images","title":"Getting the images","text":"<p>The <code>OmeZarrPlate</code> object provides a method to get the image objects in a well. The method <code>get_well_images</code> takes the row and column indices of the well and returns a list of <code>OmeZarrContainer</code> objects.</p> All ImagesAll Images in a WellSpecific ImageFilter by Acquisition <p>Get all images in the plate: <pre><code>&gt;&gt;&gt; ome_zarr_plate.get_images()\n&gt;&gt;&gt; ome_zarr_plate\n{'B/03/0': OmeZarrContainer(levels=5, #labels=5, #tables=8)}\n</code></pre> This dictionary contains the path to the images and the corresponding <code>OmeZarrContainer</code> object.</p> <p>Get all images in a well: <pre><code>&gt;&gt;&gt; well_images = ome_zarr_plate.get_well_images(row=\"B\", column=3)\n&gt;&gt;&gt; well_images\n{'B/03/0': OmeZarrContainer(levels=5, #labels=5, #tables=8)}\n</code></pre> This dictionary contains the path to the images and the corresponding <code>OmeZarrContainer</code> object.</p> <p>Get a specific image in a well: <pre><code>&gt;&gt;&gt; ome_zarr_plate.get_image(row=\"B\", column=3, image_path=\"0\")\nOmeZarrContainer(levels=5, #labels=5, #tables=8)\n</code></pre> This will return the <code>OmeZarrContainer</code> object for the image in the well.</p> <p>In these methods, you can also filter the images by acquisition. When available, the <code>acquisition</code> parameter can be used to filter the images by acquisition id. <pre><code>&gt;&gt;&gt; well_images = ome_zarr_plate.get_well_images(row=\"B\", column=3, acquisition=0)\n&gt;&gt;&gt; well_images\n{}\n</code></pre> The <code>acquisition</code> is not required, and if not provided, an empty dictionary will be returned.</p>"},{"location":"getting_started/5_hcs/#creating-a-plate","title":"Creating a plate","text":"<p>Ngio provides a utility function to create a plate.</p> <p>The first step is to create a list of <code>ImageInWellPath</code> objects. Each <code>ImageInWellPath</code> object contains the path to the image and the corresponding well. <pre><code>from ngio import ImageInWellPath\nlist_of_images = [ImageInWellPath(path=\"0\", row=\"A\", column=0),\n                    ImageInWellPath(path=\"0\", row=\"B\", column=1),\n                    ImageInWellPath(path=\"0\", row=\"C\", column=1),\n                    ImageInWellPath(path=\"1\", row=\"A\", column=0, acquisition_id=1, acquisition_name=\"acquisition_1\"),\n]\n</code></pre></p> <p>Note</p> <p>The order in which the images are added is not important. The <code>rows</code> and <code>columns</code> attributes of the plate will be sorted in alphabetical/numerical order.</p> <p>Then, you can create the plate using the <code>create_empty_plate</code> function. <pre><code>&gt;&gt;&gt; from ngio import create_empty_plate\n&gt;&gt;&gt; plate = create_empty_plate(store=\"new_plate.zarr\", name=\"test_plate\", images=list_of_images, overwrite=True)\n&gt;&gt;&gt; plate\nPlate([rows x columns] (3 x 2))\n</code></pre></p> <p>This has created a new empty plate with the metadata correctly set. But no images have been added yet. </p>"},{"location":"getting_started/5_hcs/#modifying-the-plate","title":"Modifying the plate","text":"<p>You can add images or remove images</p> Add ImagesRemove Images <p>To add images to the plate, you can use the <code>add_image</code> method. This method takes the row and column indices of the well and the path to the image. <pre><code>&gt;&gt;&gt; print(f\"Before adding images: {plate.rows} rows, {plate.columns} columns\")\n&gt;&gt;&gt; plate.add_image(row=\"D\", column=0, image_path=\"0\")\n&gt;&gt;&gt; print(f\"After adding images: {plate.rows} rows, {plate.columns} columns\")\nBefore adding images: ['A', 'B', 'C'] rows, ['0', '1'] columns\nAfter adding images: ['A', 'B', 'C', 'D'] rows, ['0', '1'] columns\n</code></pre> This will add a new image to the plate and well metadata.</p> <p>Note</p> <p>The order in which the images are added is not important. The <code>rows</code> and <code>columns</code> attributes of the plate will be sorted in alphabetical/numerical order.</p> <p>Warning</p> <p>This function is not multiprocessing safe. If you are using multiprocessing, you should use the <code>atomic_add_image</code> method instead.</p> <p>To remove images from the plate, you can use the <code>remove_image</code> method. This method takes the row and column indices of the well and the path to the image. <pre><code>&gt;&gt;&gt; print(f\"Before removing images: {plate.wells_paths()} wells\")\n&gt;&gt;&gt; plate.remove_image(row=\"D\", column=0, image_path=\"0\")\n&gt;&gt;&gt; print(f\"After removing images: {plate.wells_paths()} wells\")\nBefore removing images: ['A/0', 'B/1', 'C/1', 'D/0'] wells\nAfter removing images: ['A/0', 'B/1', 'C/1'] wells\n</code></pre> This will remove the image metadata from the plate and well metadata.</p> <p>Warning</p> <p>No data will be removed from the store. If an image is saved in the store it will remain there. Also the metadata will only be removed from the plate.well metadata. The number of columns and rows will not be updated. This function is not multiprocessing safe. If you are using multiprocessing, you should use the <code>atomic_remove_image</code> method instead.</p>"},{"location":"tutorials/feature_extraction/","title":"Feature Extraction","text":""},{"location":"tutorials/feature_extraction/#feature-extraction","title":"Feature Extraction\u00b6","text":"<p>Coming soon! This section is still under construction. Please check back later for updates.</p>"},{"location":"tutorials/hcs_processing/","title":"HCS Processing","text":""},{"location":"tutorials/hcs_processing/#hcs-processing","title":"HCS Processing\u00b6","text":"<p>Coming soon! This section is still under construction. Please check back later for updates.</p>"},{"location":"tutorials/image_processing/","title":"Image Processing","text":""},{"location":"tutorials/image_processing/#image-processing","title":"Image Processing\u00b6","text":"<p>Coming soon! This section is still under construction. Please check back later for updates.</p>"},{"location":"tutorials/image_segmentation/","title":"Image Semgmentation","text":"In\u00a0[1]: Copied! <pre># Setup a simple segmentation function\nimport numpy as np\nimport skimage\n\n\ndef otsu_threshold_segmentation(image: np.ndarray, max_label: int) -&gt; np.ndarray:\n    \"\"\"Simple segmentation using Otsu thresholding.\"\"\"\n    threshold = skimage.filters.threshold_otsu(image)\n    binary = image &gt; threshold\n    label_image = skimage.measure.label(binary)\n    label_image += max_label\n    label_image = np.where(binary, label_image, 0)\n    return label_image\n</pre> # Setup a simple segmentation function import numpy as np import skimage   def otsu_threshold_segmentation(image: np.ndarray, max_label: int) -&gt; np.ndarray:     \"\"\"Simple segmentation using Otsu thresholding.\"\"\"     threshold = skimage.filters.threshold_otsu(image)     binary = image &gt; threshold     label_image = skimage.measure.label(binary)     label_image += max_label     label_image = np.where(binary, label_image, 0)     return label_image In\u00a0[2]: Copied! <pre>from pathlib import Path\n\nfrom ngio import open_ome_zarr_container\nfrom ngio.utils import download_ome_zarr_dataset\n\n# Download the dataset\ndownload_dir = Path(\".\").absolute().parent.parent / \"data\"\nhcs_path = download_ome_zarr_dataset(\"CardiomyocyteTiny\", download_dir=download_dir)\nimage_path = hcs_path / \"B\" / \"03\" / \"0\"\n\n# Open the ome-zarr container\nome_zarr = open_ome_zarr_container(image_path)\n</pre> from pathlib import Path  from ngio import open_ome_zarr_container from ngio.utils import download_ome_zarr_dataset  # Download the dataset download_dir = Path(\".\").absolute().parent.parent / \"data\" hcs_path = download_ome_zarr_dataset(\"CardiomyocyteTiny\", download_dir=download_dir) image_path = hcs_path / \"B\" / \"03\" / \"0\"  # Open the ome-zarr container ome_zarr = open_ome_zarr_container(image_path) <pre>Downloading data from 'https://zenodo.org/records/13305156/files/20200812-CardiomyocyteDifferentiation14-Cycle1.zarr.zip' to file '/home/runner/work/ngio/ngio/data/20200812-CardiomyocyteDifferentiation14-Cycle1.zarr.zip'.\n</pre> <pre>Unzipping contents of '/home/runner/work/ngio/ngio/data/20200812-CardiomyocyteDifferentiation14-Cycle1.zarr.zip' to '/home/runner/work/ngio/ngio/data/'\n</pre> In\u00a0[3]: Copied! <pre># First we will need the image object and the FOVs table\nimage = ome_zarr.get_image()\nroi_table = ome_zarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\")\n\n# Second we need to derive a new label image to use as target for the segmentation\n\nlabel = ome_zarr.derive_label(\"new_label\", overwrite=True)\n\nmax_label = 0  # We will use this to avoid label collisions\nfor roi in roi_table.rois():\n    image_data = image.get_roi(roi=roi, c=0)  # Get the image data for the ROI\n\n    image_data = image_data.squeeze()  # Remove the channel dimension\n    roi_segmentation = otsu_threshold_segmentation(\n        image_data, max_label\n    )  # Segment the image\n\n    max_label = roi_segmentation.max()  # Get the max label for the next iteration\n\n    label.set_roi(\n        roi=roi, patch=roi_segmentation\n    )  # Write the segmentation to the label image\n</pre> # First we will need the image object and the FOVs table image = ome_zarr.get_image() roi_table = ome_zarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\")  # Second we need to derive a new label image to use as target for the segmentation  label = ome_zarr.derive_label(\"new_label\", overwrite=True)  max_label = 0  # We will use this to avoid label collisions for roi in roi_table.rois():     image_data = image.get_roi(roi=roi, c=0)  # Get the image data for the ROI      image_data = image_data.squeeze()  # Remove the channel dimension     roi_segmentation = otsu_threshold_segmentation(         image_data, max_label     )  # Segment the image      max_label = roi_segmentation.max()  # Get the max label for the next iteration      label.set_roi(         roi=roi, patch=roi_segmentation     )  # Write the segmentation to the label image <pre>/tmp/ipykernel_2564/4229125940.py:3: DeprecationWarning: The 'check_type' argument is deprecated, and will be removed in ngio=0.3. Use 'get_table_as' instead or one of the type specific get_*table() methods.\n  roi_table = ome_zarr.get_table(\"FOV_ROI_table\", check_type=\"roi_table\")\n</pre> In\u00a0[4]: Copied! <pre>label.consolidate()\n</pre> label.consolidate() In\u00a0[5]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\n\nrand_cmap = np.random.rand(1000, 3)\nrand_cmap[0] = 0\nrand_cmap = ListedColormap(rand_cmap)\n\nfig, axs = plt.subplots(2, 1, figsize=(8, 4))\naxs[0].set_title(\"Original image\")\naxs[0].imshow(image.get_array(c=0, z=1).squeeze(), cmap=\"gray\")\naxs[1].set_title(\"Final segmentation\")\naxs[1].imshow(label.get_array(z=1).squeeze(), cmap=rand_cmap)\nfor ax in axs:\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np from matplotlib.colors import ListedColormap  rand_cmap = np.random.rand(1000, 3) rand_cmap[0] = 0 rand_cmap = ListedColormap(rand_cmap)  fig, axs = plt.subplots(2, 1, figsize=(8, 4)) axs[0].set_title(\"Original image\") axs[0].imshow(image.get_array(c=0, z=1).squeeze(), cmap=\"gray\") axs[1].set_title(\"Final segmentation\") axs[1].imshow(label.get_array(z=1).squeeze(), cmap=rand_cmap) for ax in axs:     ax.axis(\"off\") plt.tight_layout() plt.show()"},{"location":"tutorials/image_segmentation/#image-semgmentation","title":"Image Semgmentation\u00b6","text":"<p>This is a minimal tutorial on how to use ngio for image segmentation.</p>"},{"location":"tutorials/image_segmentation/#step-1-setup","title":"Step 1: Setup\u00b6","text":"<p>We will first implement a very simple function to segment an image. We will use skimage to do this.</p>"},{"location":"tutorials/image_segmentation/#step-2-open-the-omezarr-container","title":"Step 2: Open the OmeZarr container\u00b6","text":""},{"location":"tutorials/image_segmentation/#step-3-segment-the-image","title":"Step 3: Segment the image\u00b6","text":"<p>For this example, we will not segment the image all at once. Instead we will iterate over the image FOVs and segment them one by one.</p>"},{"location":"tutorials/image_segmentation/#step-4-consolidate-the-segmentation","title":"Step 4: Consolidate the segmentation\u00b6","text":"<p>The <code>new_label</code> has data only at a single resolution lebel. To consolidate the segmentation to all other levels we will need to call the <code>consolidate</code> method.</p>"},{"location":"tutorials/image_segmentation/#plot-the-segmentation","title":"Plot the segmentation\u00b6","text":""}]}